# Language Modeling and Text Generation

Using probability to making language models. See demonstration.ipynb to see demonstration, project.py to see back end code.

- Built statistical language models (Uniform, Unigram, N-gram) for realistic text generation and sequence prediction
- Designed web scraper to download and preprocess books with requests and regex, optimizing data extraction
- Created a custom tokenization pipeline to streamline NLP data preparation and sequence modeling
